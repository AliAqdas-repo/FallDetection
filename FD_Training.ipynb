{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FD_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNCq+UO+jdcZRqq0obuxIkU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliAqdas-repo/FallDetection/blob/main/FD_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Dependencies"
      ],
      "metadata": {
        "id": "WPK58gc4pnxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "id": "zIoBGfSxpnT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Dependencies"
      ],
      "metadata": {
        "id": "Z-OM8Ve1dCVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ix99qVlVc96O"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import plotly.express as px\n",
        "import seaborn as sn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Downloading Processed Dataset from Google Drive\n",
        "We are downloading the dataset we prepared the Data Organization Notebook of this project. We have already prepared the dataset and made it available on Google Drive. You can simply download it over the Google Server to Colab"
      ],
      "metadata": {
        "id": "Y1yETLfAdOSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1YV106cRSbZu6txcPdi2iMA8xDOfe8-6b #Contains all Sensor Data contrary to what we did in Previous Notebook"
      ],
      "metadata": {
        "id": "Zw1nbxwqdFwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzipping the Dataset\n",
        "!unzip data_proc.zip\n",
        "!mv /content/content/data_proc /content/data_proc\n",
        "shutil.rmtree('/content/content')"
      ],
      "metadata": {
        "id": "57bRkMwBe9n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Reading Functions\n",
        "We initially define some functions to be used later for reading the processed data."
      ],
      "metadata": {
        "id": "iRkA2c15nfDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_full_path(dir):\n",
        "  return [os.path.join(dir,os.path.splitext(fi)[0]) for fi in os.listdir(dir)]"
      ],
      "metadata": {
        "id": "MfYyZORXn3OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_into_array(filedir):\n",
        "  #reads data into array. If file extension isn't displayed in filedir then its default to .dat\n",
        "  ext=os.path.splitext(filedir)[1]\n",
        "  if ext=='':\n",
        "    ext='.dat'\n",
        "  with open(os.path.splitext(filedir)[0]+ext,'r') as datfile :\n",
        "    file_data=csv.reader(datfile,delimiter=',')\n",
        "    data=list()\n",
        "    for row in file_data:\n",
        "      data.append([float(val) for val in row])\n",
        "  return data"
      ],
      "metadata": {
        "id": "oASSrbR8fJsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization\n",
        "We are using Plotly, a library which allows us to give amazing pictorial representation of different types of data\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qE8iXLbopefZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ply_plot(datpath):\n",
        "  dat=np.asarray(read_into_array(f'{datpath}.csv'))\n",
        "  import plotly.graph_objects as go\n",
        "  if not np.shape(dat)[1]<10:\n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "                      z=dat,\n",
        "                      x=[r'$a_{x}$',r'$a_{y}$',r'$a_{z}$',r'$b$',r'$g_{x}$',r'$g_{y}$',r'$g_{z}$',r'$m_{x}$',r'$m_{y}$',r'$m_{z}$'],\n",
        "                      hoverongaps = False,colorbar={\"title\":'Sensor Reading'}))\n",
        "\n",
        "  else:\n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "                      z=dat,\n",
        "                      x=[r'$a_{x}$',r'$a_{y}$',r'$a_{z}$',r'$g_{x}$',r'$g_{y}$',r'$g_{z}$'],\n",
        "                      hoverongaps = False,colorbar={\"title\":'Sensor Reading'}))\n",
        "\n",
        "  fig.update_layout(\n",
        "      xaxis_title=r'$Sensor\\ Labels$',\n",
        "      yaxis_title=r'$Time\\ Axis$',)\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "jwlIjTx-qH4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Fall Data\n",
        "datpath=sorted(list_full_path('/content/data_proc/fall_files'))[10]\n",
        "ply_plot(datpath)"
      ],
      "metadata": {
        "id": "6QmPErj-qCQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Activities of Daily Life (ADLs) Data\n",
        "datpath=sorted(list_full_path('/content/data_proc/not_fall_files'))[0]\n",
        "ply_plot(datpath)"
      ],
      "metadata": {
        "id": "sE2H6GkbqJXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "CZtaEUdv9szk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DONOT USE PANDAS. Issue with Reading Data. Reads one point less\n",
        "def csv_dataloader(Path,auto_balance=False,skip_wrist=False):\n",
        "  ###### Parameters #######\n",
        "  # Path = Path to Data(Classes need to be split in different folders beforehand)\n",
        "  # auto_balance = Balances Data by Trimming Extra Data\n",
        "  # skip_wrist = Skips Samples from Wrist Measurements (as they are prone to errors)\n",
        "  #########################\n",
        "  classes=len(os.listdir(Path)) #number of classes\n",
        "  dirs=[os.path.join(Path,folds) for folds in os.listdir(Path)]\n",
        "  data=[]\n",
        "  lbls=[]\n",
        "  file_lbl=0\n",
        "  min_len=0\n",
        "  len_hist=[]\n",
        "  if auto_balance:\n",
        "    for dir in dirs:\n",
        "      data_files=sorted(list_full_path(dir))\n",
        "      if skip_wrist:\n",
        "        data_files=[data_file for data_file in data_files if data_file[35]!='2']\n",
        "      len_hist.append(len(data_files))\n",
        "    min_len=min(len_hist)\n",
        "  for dir in dirs:\n",
        "    data_files=sorted(list_full_path(dir))\n",
        "    if skip_wrist:\n",
        "      data_files=[data_file for data_file in data_files if data_file[35]!='2']\n",
        "    if auto_balance:\n",
        "      data_files=data_files[:min_len-1]\n",
        "    dir_data=[]\n",
        "    dir_lbls=[]\n",
        "    for data_file in data_files:\n",
        "      file_data=np.expand_dims(np.asarray(read_into_array(f'{data_file}.csv')),2)\n",
        "      dir_lbls.append(np.array(file_lbl))\n",
        "      dir_data.append(file_data)\n",
        "    file_lbl+=1\n",
        "    data.append(np.array(dir_data))\n",
        "    lbls.append(np.array(dir_lbls))\n",
        "  data=np.concatenate(tuple(data),0)\n",
        "  lbls=np.concatenate(tuple(lbls),0)  \n",
        "  return tf.data.Dataset.from_tensor_slices((data.astype(np.float32),lbls.astype(np.int8)))"
      ],
      "metadata": {
        "id": "OuL3iZfO9wrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0=Fall 1=No Fall\n",
        "loader=csv_dataloader('/content/data_proc/',False,False)"
      ],
      "metadata": {
        "id": "PJUEwnXW-e7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset Characteristics\n",
        "loader.element_spec"
      ],
      "metadata": {
        "id": "IhGi61JC-jby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting Data in Train,Validation and Test"
      ],
      "metadata": {
        "id": "fGoEmWWJ-97Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def splitds(dataset,train_ratio,val_ratio,test_ratio=0,shuffle=False,shuffle_buffer=5000):\n",
        "  assert train_ratio+val_ratio+test_ratio==1\n",
        "  SEED=32768;\n",
        "  if shuffle==True:\n",
        "    dataset=dataset.shuffle(shuffle_buffer,seed=SEED)\n",
        "  \n",
        "  ds_size=len(dataset)\n",
        "  train_ds=dataset.take(int(ds_size*train_ratio))\n",
        "  val_ds=dataset.skip(int(train_ratio*ds_size)).take(int(ds_size*val_ratio))\n",
        "  if not test_ratio==0:\n",
        "    test_ds=dataset.skip(int((train_ratio+val_ratio)*ds_size)).take(int(ds_size*test_ratio))\n",
        "    return train_ds,val_ds,test_ds\n",
        "\n",
        "  return train_ds,val_ds"
      ],
      "metadata": {
        "id": "GLaftHY0-q9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds,val_ds,test_ds=splitds(loader,0.8,0.1,0.1,shuffle=True,shuffle_buffer=10000)"
      ],
      "metadata": {
        "id": "1m-pFrJ4-6mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ds))\n",
        "print(len(val_ds))\n",
        "print(len(test_ds))"
      ],
      "metadata": {
        "id": "Kskzxmqe-9Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "WnWv1c7C_NCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential(\n",
        "    [tf.keras.layers.Conv2D(16,(3,2),activation='relu',input_shape=(952,10,1)),\n",
        "     tf.keras.layers.MaxPool2D((2,1)),\n",
        "     tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2,1)),\n",
        "     tf.keras.layers.Conv2D(64,(3,1),activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2,1)),\n",
        "     tf.keras.layers.Conv2D(128,(3,1),activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2,1)),    \n",
        "     tf.keras.layers.Conv2D(256,(3,1),activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2,1)), \n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "h53vy5JN_OGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "pN9fugJZ_Qvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(0.0005),loss='binary_crossentropy',metrics=['accuracy','FalsePositives','FalseNegatives'])"
      ],
      "metadata": {
        "id": "yRjoPlMt_dGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "!rm -rf ./logs/\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "PEZ6c0Y9_eWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_callback=tf.keras.callbacks.ReduceLROnPlateau('val_loss',factor=0.1,patience=2)\n",
        "with tf.device('/device:GPU:0'):\n",
        "  history=model.fit(train_ds.batch(1),validation_data=val_ds.batch(1),epochs=10,callbacks=[tensorboard_callback,lr_callback])"
      ],
      "metadata": {
        "id": "Vgucjg2q_fWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "8oQLxY-t_nKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Predictions\n",
        "We are running predictions on our trained model so we can quantify it accuracy on unseen data"
      ],
      "metadata": {
        "id": "5fJUtC48_s9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#0 = fall , 1 = No Fall\n",
        "preds=model.predict(test_ds.batch(1))\n",
        "pred_lbls=np.squeeze(np.where(preds>0.6,1,0))"
      ],
      "metadata": {
        "id": "iUaH-UEN_vQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lbls"
      ],
      "metadata": {
        "id": "yZ5SCzmu_0D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truth_lbls = np.concatenate([y for x, y in test_ds.batch(1)], axis=0)\n",
        "np.asarray(tf.math.confusion_matrix(truth_lbls,pred_lbls,2)).astype(np.int16)"
      ],
      "metadata": {
        "id": "JtcNopx6__3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bininopaul https://stackoverflow.com/a/35572247/13223282\n",
        "cm=np.asarray(tf.math.confusion_matrix(truth_lbls,pred_lbls,2))\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in ['Fall','Not Fall']],\n",
        "                  columns = [i for i in ['Fall','Not Fall']])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True,fmt='g')"
      ],
      "metadata": {
        "id": "tVHob8-RABSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Training using only Two Sensors Data\n",
        "Let's try using only accelerometer and gyroscope data"
      ],
      "metadata": {
        "id": "iUVJg7PsA8Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Accelrometer and Gyro Only\n",
        "!gdown --id 1dICsvfTAV0ZDDNHVR6sYwix-NgyQDPwB "
      ],
      "metadata": {
        "id": "eqysRyAOBWx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data_proc_AG.zip\n",
        "!mv /content/content/data_proc_AG /content/data_proc_AG\n",
        "shutil.rmtree('/content/content')"
      ],
      "metadata": {
        "id": "wFQrzm6wBZZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Fall Data\n",
        "datpath=sorted(list_full_path('/content/data_proc_AG/fall_files'))[10]\n",
        "ply_plot(datpath)"
      ],
      "metadata": {
        "id": "8WbDrmBpBdAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot ADLs\n",
        "datpath=sorted(list_full_path('/content/data_proc/not_fall_files'))[0]\n",
        "ply_plot(datpath)"
      ],
      "metadata": {
        "id": "ett0fIkYBkHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0=Fall 1=No Fall\n",
        "loader=csv_dataloader('/content/data_proc_AG/',False,False)"
      ],
      "metadata": {
        "id": "tvvWq5t3BsPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader.element_spec"
      ],
      "metadata": {
        "id": "zvrMT0xBBv7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds,val_ds,test_ds=splitds(loader,0.8,0.1,0.1,shuffle=True,shuffle_buffer=10000)"
      ],
      "metadata": {
        "id": "v9MoImLsByOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ds))\n",
        "print(len(val_ds))\n",
        "print(len(test_ds))"
      ],
      "metadata": {
        "id": "y3hDAtJcB0Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential(\n",
        "    [tf.keras.layers.Conv2D(16,(3,2),activation='relu',input_shape=(952,6,1)),\n",
        "     tf.keras.layers.MaxPool2D((2,1)),\n",
        "     tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2,1)),\n",
        "     tf.keras.layers.Conv2D(64,(3,1),activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2,1)),\n",
        "     tf.keras.layers.Conv2D(128,(3,1),activation='relu'),\n",
        "     tf.keras.layers.MaxPool2D((2,1)),    \n",
        "     tf.keras.layers.Conv2D(256,(3,1),activation='relu'), ##\n",
        "     tf.keras.layers.MaxPool2D((2,1)), ## \n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "eoByaN-WB1mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "DvSS5pi4B3q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(0.0005),loss='binary_crossentropy',metrics=['accuracy','FalsePositives','FalseNegatives'])"
      ],
      "metadata": {
        "id": "7F7XQIJiB7GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "!rm -rf ./logs/\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "L8VKrIHRB9wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_callback=tf.keras.callbacks.ReduceLROnPlateau('val_loss',factor=0.1,patience=2)\n",
        "with tf.device('/device:GPU:0'):\n",
        "  history=model.fit(train_ds.batch(1),validation_data=val_ds.batch(1),epochs=10,callbacks=[tensorboard_callback,lr_callback])"
      ],
      "metadata": {
        "id": "Gz8I10uLCBEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "LA7Urk-aCCsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0 = fall , 1 = No Fall\n",
        "preds=model.predict(test_ds.batch(1))\n",
        "pred_lbls=np.squeeze(np.where(preds>0.6,1,0))\n",
        "truth_lbls = np.concatenate([y for x, y in test_ds.batch(1)], axis=0)\n",
        "np.asarray(tf.math.confusion_matrix(truth_lbls,pred_lbls,2)).astype(np.int16)"
      ],
      "metadata": {
        "id": "KdhzzDcqCEAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Confusion Matrix\n",
        "cm=np.asarray(tf.math.confusion_matrix(truth_lbls,pred_lbls,2))\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in ['Fall','Not Fall']],\n",
        "                  columns = [i for i in ['Fall','Not Fall']])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True,fmt='g')"
      ],
      "metadata": {
        "id": "CzSileNlCJS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have trained our model on both datasets. Observe which one performs better by viewing the confusion matrix. Our model is now ready to be optimized and converted to FlatBuffer format to be used in Arduino."
      ],
      "metadata": {
        "id": "toB1SA3-CMMz"
      }
    }
  ]
}